{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  # Python for Data Science Bootcamp\n",
    "  ## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the iris CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "species         150 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 5.9 KB\n",
      "None\n",
      "       sepal_length  sepal_width  petal_length  petal_width     species\n",
      "count    150.000000   150.000000    150.000000   150.000000  150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667    1.000000\n",
      "std        0.828066     0.433594      1.764420     0.763161    0.819232\n",
      "min        4.300000     2.000000      1.000000     0.100000    0.000000\n",
      "25%        5.100000     2.800000      1.600000     0.300000    0.000000\n",
      "50%        5.800000     3.000000      4.350000     1.300000    1.000000\n",
      "75%        6.400000     3.300000      5.100000     1.800000    2.000000\n",
      "max        7.900000     4.400000      6.900000     2.500000    2.000000\n"
     ]
    }
   ],
   "source": [
    "print iris.info()\n",
    "print iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two variables for features and target.  Convert them into values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_features = iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].values\n",
    "iris_target = iris.species.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn has a function to split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply train_test_split to sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_features = [[1,10],[2,20],[3,30],[4,40],[5,50]]\n",
    "example_target = ['a','b','c','d','e']\n",
    "\n",
    "f_train, f_test, t_train, t_test = train_test_split(example_features, example_target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View results of train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "[[1, 10], [2, 20], [4, 40], [5, 50]]\n",
      "['a', 'b', 'd', 'e'] \n",
      "\n",
      "\n",
      "Test Set\n",
      "[[3, 30]]\n",
      "['c']\n"
     ]
    }
   ],
   "source": [
    "print 'Training Set'\n",
    "print f_train\n",
    "print t_train,'\\n\\n'\n",
    "print 'Test Set'\n",
    "print f_test\n",
    "print t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the iris data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "        iris_features, iris_target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120,)\n",
      "(30,)\n",
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "print target_train.shape\n",
    "print target_test.shape\n",
    "print features_train.shape\n",
    "print features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the K Nearest Neighbors classifier from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(5,weights='distance').fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predictions with actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print model.predict(features_test)\n",
    "print target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.21628456,  0.78371544],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.58205246,  0.41794754],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.84820868,  0.15179132],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.12858452,  0.87141548],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the KFold function from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold function creates indices for separating training and test sets.  Lets create indices for a data set of 3 records with 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=3, n_folds=3, shuffle=False, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "k_fold_indices = KFold(3, n_folds=3, shuffle=False)\n",
    "print k_fold_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is in the k_fold_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [0]\n",
      "[0 2] [1]\n",
      "[0 1] [2]\n"
     ]
    }
   ],
   "source": [
    "for x,y in k_fold_indices:\n",
    "    print x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how to index numpy arrays with indices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40  0 20]\n"
     ]
    }
   ],
   "source": [
    "sample = np.array([0,10,20,30,40,50])\n",
    "indices = [4,0,2]\n",
    "print sample[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the indices to index values in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b' 'c'] ['a']\n",
      "['a' 'c'] ['b']\n",
      "['a' 'b'] ['c']\n"
     ]
    }
   ],
   "source": [
    "data = np.array(['a','b','c'])\n",
    "for x,y in k_fold_indices:\n",
    "    print data[x], data[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation function with average score\n",
    "def cross_validate(features, target, classifier, k_fold, r_state=None) :\n",
    "\n",
    "    # derive a set of (random) training and testing indices\n",
    "    k_fold_indices = KFold(len(features), n_folds=k_fold,\n",
    "                           shuffle=True, random_state=r_state)\n",
    "\n",
    "    k_score_total = 0\n",
    "    \n",
    "    # for each training and testing slices run the classifier, and score the results\n",
    "    for train_indices, test_indices in k_fold_indices :\n",
    "\n",
    "        model = classifier.fit(features[train_indices],\n",
    "                           target[train_indices])\n",
    "\n",
    "        k_score = model.score(features[test_indices],\n",
    "                              target[test_indices])\n",
    "\n",
    "        k_score_total += k_score\n",
    "\n",
    "    # return the average accuracy\n",
    "    return k_score_total/k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  5  6  7  8  9 10 11 12 14 15 17 18 19]  -  [ 3  4 13 16]\n",
      "[ 0  1  3  4  5  6  8 10 11 12 13 14 15 16 17 18]  -  [ 2  7  9 19]\n",
      "[ 0  2  3  4  5  6  7  9 10 11 13 14 15 16 18 19]  -  [ 1  8 12 17]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 12 13 14 16 17 19]  -  [ 0 11 15 18]\n",
      "[ 0  1  2  3  4  7  8  9 11 12 13 15 16 17 18 19]  -  [ 5  6 10 14]\n"
     ]
    }
   ],
   "source": [
    "k_fold_indices = KFold(20, 5, shuffle=True)\n",
    "\n",
    "for train_indices, test_indices in k_fold_indices :\n",
    "    print train_indices, ' - ',test_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cross-validation on the iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "print cross_validate(iris_features, iris_target, \n",
    "                     KNeighborsClassifier(3), 10, 0)\n",
    "print cross_validate(iris_features, iris_target, \n",
    "                     KNeighborsClassifier(4,weights='distance'), 10, 0)\n",
    "print cross_validate(iris_features, iris_target, \n",
    "                     KNeighborsClassifier(5,weights='distance'), 10, 0)\n",
    "print cross_validate(iris_features, iris_target, \n",
    "                     KNeighborsClassifier(6), 10, 0)\n",
    "print cross_validate(iris_features, iris_target, \n",
    "                     KNeighborsClassifier(7), 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "#### 1. Load the clean_data.csv as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null bool\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "Pclass_1       891 non-null float64\n",
      "Pclass_2       891 non-null float64\n",
      "Pclass_3       891 non-null float64\n",
      "dtypes: bool(1), float64(5), int64(5), object(4)\n",
      "memory usage: 98.4+ KB\n",
      "None\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name    Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris   True  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  False  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  False  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  False  35.0      1   \n",
      "4                           Allen, Mr. William Henry   True  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  Pclass_1  Pclass_2  \\\n",
      "0      0         A/5 21171   7.2500   NaN        S       0.0       0.0   \n",
      "1      0          PC 17599  71.2833   C85        C       1.0       0.0   \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S       0.0       0.0   \n",
      "3      0            113803  53.1000  C123        S       1.0       0.0   \n",
      "4      0            373450   8.0500   NaN        S       0.0       0.0   \n",
      "\n",
      "   Pclass_3  \n",
      "0       1.0  \n",
      "1       0.0  \n",
      "2       1.0  \n",
      "3       0.0  \n",
      "4       1.0  \n"
     ]
    }
   ],
   "source": [
    "# Load data into DataFrame\n",
    "data = pd.read_csv('clean_data.csv')\n",
    "\n",
    "print data.info()\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Separate the data into features (limit to age, sex, pclass dummy variables) and target (Note: Make sure you convert the data to a numpy array by typing .values at end of DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create features and target variables as numpy arrays\n",
    "features = data[['Age','Sex','Pclass_1','Pclass_2','Pclass_3']].values\n",
    "\n",
    "target = data['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Build a KNN model and test the accuracy of the model using kfold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75645443196004991"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(features, target, KNeighborsClassifier(3), 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Create a for loop to test different numbers of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756529338327\n",
      "0.786754057428\n",
      "0.793483146067\n",
      "0.799088639201\n",
      "0.792347066167\n",
      "0.795717852684\n",
      "0.793508114856\n",
      "0.793508114856\n",
      "0.794631710362\n",
      "0.794631710362\n",
      "0.793508114856\n",
      "0.791260923845\n",
      "0.79013732834\n",
      "0.787890137328\n",
      "0.786766541823\n",
      "0.784519350811\n",
      "0.787890137328\n",
      "0.786766541823\n",
      "0.787890137328\n",
      "0.787890137328\n",
      "0.786766541823\n",
      "0.785642946317\n",
      "0.784519350811\n",
      "0.786766541823\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,120,5):\n",
    "    model = KNeighborsClassifier(k, weights='distance')\n",
    "    print cross_validate(features, target, model, 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_age = data.Age.mean()\n",
    "stdev_age = data.Age.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract the mean and divide by the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Age_norm'] = (data.Age - avg_age)/stdev_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features using normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_norm = data[['Age_norm','Sex','Pclass_1','Pclass_2','Pclass_3']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test KNN on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762059925094\n",
      "0.797952559301\n",
      "0.790149812734\n",
      "0.80138576779\n",
      "0.796903870162\n",
      "0.801360799001\n",
      "0.802496878901\n",
      "0.80024968789\n",
      "0.799138576779\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    model = KNeighborsClassifier(k)\n",
    "    print cross_validate(features_norm, target, model, 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Random Forest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of a random forest classifier.  Random state is used to set random number generator for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cross-validation function using the Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80475655430711623"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(features, target, model, 10, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4359133   0.40366222  0.05078753  0.02608483  0.08355212]\n"
     ]
    }
   ],
   "source": [
    "print model.fit(features,target).feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- Implement the random forest algorithm on the titanic data\n",
    "- Review the random forest algorithm model parameters on sklearn \n",
    "- Adjust parameters to get the best model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = data[['Age', 'Sex', 'Pclass_1','Pclass_2','Pclass_3']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80474406991260916"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, max_depth=None, min_samples_split=2, \n",
    "                               min_samples_leaf=2,random_state=None)\n",
    "cross_validate(features, target, model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799126092385\n",
      "0.818214731586\n",
      "0.818214731586\n",
      "0.820449438202\n",
      "0.812621722846\n",
      "0.811498127341\n",
      "0.812496878901\n"
     ]
    }
   ],
   "source": [
    "for n in [5,10,20,30,40,50,100]:\n",
    "    model = RandomForestClassifier(n_estimators=n, max_depth=None, min_samples_split=2, \n",
    "                               min_samples_leaf=2)\n",
    "    print cross_validate(features, target, model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction for Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the best data available (in the case of the Titanic you'd use all the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = data[['Age', 'Sex', 'Pclass_1','Pclass_2','Pclass_3']].values\n",
    "target = data.Survived.values\n",
    "model = RandomForestClassifier(random_state=0).fit(features,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the predict and predict_proba functions within the trained model to predict future events (remember to normalize data before entering it into the model - you'll have to subract the mean and divide by the standard deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame with the test.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000         NaN    0.000000    0.000000         NaN\n",
      "50%    1100.500000    3.000000         NaN    0.000000    0.000000         NaN\n",
      "75%    1204.750000    3.000000         NaN    1.000000    0.000000         NaN\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Craig_Sakuma/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "print test_data.head()\n",
    "print test_data.info()\n",
    "print test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.Sex = test_data.Sex.replace(['male','female'],[True,False])\n",
    "avg_age = test_data.Age.mean()\n",
    "test_data.Age = test_data.Age.fillna(avg_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Pclass to dummies and merge to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null bool\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "Pclass_1       418 non-null float64\n",
      "Pclass_2       418 non-null float64\n",
      "Pclass_3       418 non-null float64\n",
      "dtypes: bool(1), float64(5), int64(4), object(4)\n",
      "memory usage: 42.9+ KB\n"
     ]
    }
   ],
   "source": [
    "pclass = pd.get_dummies(test_data.Pclass, prefix = 'Pclass')\n",
    "test_data = pd.merge(test_data,pclass,left_index=True,right_index=True)\n",
    "\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features from test data and convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test_data[['Age','Sex','Pclass_1','Pclass_2','Pclass_3']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions =  model.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Predictions as new column in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['Survived'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as CSV (make sure you set index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle = test_data[['PassengerId','Survived']]\n",
    "kaggle.to_csv('kaggle_titanic_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
